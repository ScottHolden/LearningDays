# Part 2 - Taking it to production
## Overview
In this section we will cover off common scenarios for advanced use of Azure OpenAI, including steps to production, RAG patterns & embeddings, and security techniques.

Each steps contain the following sections:
- **Aim**: The goal of the step, will instruct what to do but not how
- **Questions**: A set of follow-up questions to self-test your knowledge
- **Resources**: Documentation links to help guide you if you get stuck
- **Stretch**: A secondary goal to either push yourself, or revisit later

## Step 1 - Using Managed Identity for Azure OpenAI
### Aim
Using either your code from Part 1, or a sample app [found here](https://github.com/ScottHolden/SimplePrompt-Starter), remove any API keys or Azure OpenAI keys. Ensure everything works as before.

### Questions
- What permissions do you need to call Azure OpenAI?
- Are there any in-built roles?
- How do SDK options such as DefaultAzureCredential work locally & in Azure?
- What about the BYO data extension Azure AI Search keys?

### Resources
- https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/managed-identity
- https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview
- https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/use-your-data-securely

### Stretch
Update your template from Part 1 to include a user-assigned managed identity, and a role assignment with least permissions.

## Step 2 - Configuring private networking for Azure OpenAI
### Aim
Using the WebApp from part 1, set up a vnet and private endpoint for Azure OpenAI and vnet inject the WebApp. You should be able to disable all external access to the Azure OpenAI resource expect via the Private Endpoint.

### Questions
- Were there any considerations or additional services required besides the ones listed above?
- How would limiting access to only a Private Endpoint affect Azure OpenAI Studio?
- How could developers still access Azure OpenAI when a Private Endpoint is configured?
- What are the benefits of using a Private Endpoint for Azure OpenAI?

### Resources
- https://learn.microsoft.com/en-us/azure/ai-services/cognitive-services-virtual-networks

### Stretch
Add a vnet and private endpoint to your template from Part 1 along with any supporting resources, rewrite the Azure OpenAI resource to only accept traffic from the private endpoint.

## Step 3 - Generating Embeddings
### Aim
Using either the REST API or an Azure OpenAI SDK, generate embeddings for a set of text. Write the embeddings to either the console, or a file. Repeat for multiple sets of text and compare.

### Questions
- How does generating embeddings compare to chat completions?
- How many dimensions does your embedding have?
- Does smaller/larger text have a different embedding size?
- Could you use an embedding generated by one model with another model?

### Resources
- https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/embeddings
- https://learn.microsoft.com/en-us/azure/ai-services/openai/tutorials/embeddings

### Stretch
Using your language of choice perform an in-memory cosine distance (or similar) to determine how similar the sets of text are. Accept user input to create an in-memory search engine.

## Step 4 - Vector Search
### Aim
Taking the embeddings from step 3, place them into either an Azure AI Search Index, an Azure CosmosDB Mongo vCore Database, or a Azure Postgres Database. Create a simple search interface to query the data.

### Questions
- Should you store the content and the embedding? Why would/wouldn't you want to?
- What needs to happen to a users search before the database can be queried?
- How do the different database options differ?

### Resources
- https://learn.microsoft.com/en-us/azure/search/vector-search-overview
- https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/how-to-use-pgvector
- https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/vector-search

### Stretch
For your database of choice, ensure you have indexing set up.

## Step 5 - RAG (Retrieval Augmented Generation)
### Aim
Combine your chat completion code with your vector search code to create a customizable RAG implementation. Only relevant documents/text should be included in the prompt, and the response should be written to the console output.

### Questions
- Where should the RAG data be placed?
- How would you reference what data is being used?
- Does context size (max tokens in prompt) matter with RAG?
- What lifecycle management considerations does RAG introduce if any?

### Resources
- https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview
- https://github.com/Azure-Samples/chat-with-your-data-solution-accelerator
- https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/
- https://learn.microsoft.com/en-us/azure/developer/intro/azure-ai-for-developers#building-blocks-1

### Stretch
Restrict the user from asking irrelevant questions, or questions not contained within the data.

## Step 6 - Multi-region management
### Aim
Implement a multi-region fallback for any calls to Azure OpenAI in your RAG implementation. If the primary region is over quota, you should try a secondary region. You can implement this in any way you want.

### Questions
- Why does multi-region matter?
- Are there any considerations for multi-region that don't exist for single region?
- Should the client/code be aware of the multi-region setup?
- Would a similar approach work for PTU vs PAYG?

### Resources
- https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/quota?tabs=rest#understanding-rate-limits
- https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/business-continuity-disaster-recovery
- https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/provisioned-throughput#how-does-the-service-decide-when-to-send-a-429
- https://github.com/microsoft/AICentral

### Stretch
Implement multi-region fallback in a way that is completely transparent to your code, revert the code to how it was in step 5, but ensure multi-region is still working.

## Step 7 - Prompt injection defense
### Aim
Investigate alternative methods to defend against prompt injection attacks such as blocked word lists or RAG relevance checks. Implement one of these methods in your RAG implementation.

### Questions
- Why would you use a blocked word list over modifying a prompt?
- Where would/wouldn't a blocked work list work?
- What other metrics or indicators could you use to determine if a prompt is being injected?

### Resources
- https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/red-teaming
